{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTOF8uxfGbpv"
      },
      "source": [
        "# Lab 2: GPT from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWC-ZXfrGbpz"
      },
      "source": [
        "In this lab, you will dive into the inner workings of the GPT architecture. You will walk through a complete implementation of the architecture in PyTorch, instantiate this implementation with pre-trained weights, and put the resulting model to the test by generating text. At the end of this lab, you will understand the building blocks of the GPT architecture and how they are connected.\n",
        "\n",
        "*Tasks you can choose for the oral exam are marked with the graduation cap ðŸŽ“ emoji.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cj1kG5UaGbp1"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRGq_mA6Gbp3"
      },
      "source": [
        "## Part 1: GPT architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjvG2tpQGbp3"
      },
      "source": [
        "GPT-2 was first described by [Radford et al. (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf). To faithfully implement the model, one needs to also read the earlier paper by [Radford et al. (2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf). Another important source of information is the code released by OpenAI, which is available on GitHub ([link](https://github.com/openai/gpt-2)).\n",
        "\n",
        "The GPT architecture is made up of a stack of Transformer blocks. Each block has two main parts: one handles multi-head self-attention, and the other is a feed-forward network. Before these parts do their work, their input undergoes layer normalisation, and residual connections are added to help the model learn more effectively. The input to the architecture is a sequence of token IDs; these are turned into embeddings and augmented with information about the absolute position of each token in the sequence. The output layer converts the internal representations into logit scores for every token in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55-V_lotGbp4"
      },
      "source": [
        "### Model configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_v37IZGGbp4"
      },
      "source": [
        "[Radford et al. (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) present four increasingly larger GPT models based on the same architecture. Here, we will implement the smallest of these, characterised by the following hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VSxxMSvDGbp5"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    n_vocab: int = 50_257\n",
        "    n_ctx: int = 1024\n",
        "    n_embd: int = 768\n",
        "    n_head: int = 12\n",
        "    n_layer: int = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-wRV25Gbp5"
      },
      "source": [
        "#### ðŸŽˆ Task 2.01: Model configuration\n",
        "\n",
        "Explain the purpose of these hyperparameters. In particular, where does the number 50,257 come from?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI2JbKqZIGzP"
      },
      "source": [
        "- `n_vocab` is the numbner of unique tokens, the number 50_257 came from the tokenizer when the model was trained.</br>\n",
        "- `n_ctx` is the context length which is the number of tokens that the model can process at once. </br>\n",
        "- `n_embd` the number of dimensions for the embedded vectors, basically when the tokens are converted into vectors. </br>\n",
        "- `n_head` the number of multihead self attention (MHA).</br>\n",
        "- `n_layer` The number of transformer blocks taht contains MHA, FFN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgJufnRjGbp5"
      },
      "source": [
        "### GELU activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYxamTzLGbp5"
      },
      "source": [
        "We start by implementing the feed-forward network. This is a standard two-layer network with a Gaussian Error Linear Unit (GELU) activation function ([Hendrycks and Gimpel, 2016](https://doi.org/10.48550/arXiv.1606.08415)).\n",
        "\n",
        "The GELU is a smooth version of the rectified linear unit (ReLU) that weights inputs by their value under the cumulative distribution function of the standard Gaussian. This function is commonly denoted by $\\Phi$. For example, $\\text{GELU}(0{.}5) = 0{.}5 \\cdot \\Phi(0{.}5) \\approx 0{.}5 \\cdot 0{.}6915 = 0{.}3457$ because approximately 69.15% of normally distributed data lies to the left of $0{.}5$.\n",
        "\n",
        "When GPT-2 was released, computing the GELU exactly was expensive, and the released code therefore used an approximation originally presented by [Page (1977)](https://doi.org/10.2307/2346872). We follow suit here, as we want to create a replica of the original model. However, it is worth mentioning that PyTorch now offers an exact implementation of the GELU so fast that using an approximation is unnecessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lzaSJjWaGbp6"
      },
      "outputs": [],
      "source": [
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + torch.tanh((2 / torch.pi) ** 0.5 * (x + 0.044715 * x**3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On5Bx62wGbp6"
      },
      "source": [
        "#### ðŸŽ“ Task 2.02: Mathematical properties of the GELU\n",
        "\n",
        "Find the minimal output value of the (approximated) GELU and the input value for which it yields that output. Use a service such as [WolframAlpha](https://www.wolframalpha.com/) for the necessary derivations. What are the main differences between the GELU and the ReLU?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty6Bo2aDo2Lt"
      },
      "source": [
        "min{0.5 x (1 + tanh((2/Ï€)^0.5 (x + 0.044715 x^3)))}â‰ˆ-0.170041 at xâ‰ˆ-0.752461\n",
        "\n",
        "The difference between GELU and ReLU:\n",
        "The way they both are visualized since ReLU shows a a convergence at 0 where values less than 0 are non differentiable, meanwhile GELU shows smoothness that looks like a curve and it is differentiable across the entire x axis.\n",
        "With differentiable we mean that the model can learn and update parameters, so when it is always 0 it means nothing is learned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvmXolIcGbp6"
      },
      "source": [
        "### Feed-forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXwl10L6Gbp6"
      },
      "source": [
        "Next, here is the code for the feed-forward network. Note that we follow the released code and use the name **multi-layer perceptron (MLP)** rather than â€œfeed-forward networkâ€."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LARxoPLdGbp7"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, config.n_embd * 4)\n",
        "        self.c_proj = nn.Linear(config.n_embd * 4, config.n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, n_embd = x.shape\n",
        "        # shape of x [8, 1024, 768] (B, S, E)\n",
        "        x = self.c_fc(x)\n",
        "        # shape of x [8, 1024, 3072] because it has been multiplied by 4 (B, S, 4E)\n",
        "        x = gelu(x)\n",
        "        # shape of x [8, 1024, 3072] remains the same (B, S, 4E)\n",
        "        x = self.c_proj(x)\n",
        "        # shape of x [8, 1024, 768] the input dimension got compressed to it is original dimension (the same as the input) (B, S, E)\n",
        "        return x\n",
        "        # shape of x [8, 1024, 768] (B, S, E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS0REV66-42U",
        "outputId": "49391945-fe19-442c-f6f8-d9d22950ff6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1024, 3072])\n"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "mlp = MLP(config)\n",
        "batch_size = 8\n",
        "x = torch.randn( batch_size, config.n_ctx, config.n_embd)\n",
        "x = mlp.c_fc(x)\n",
        "print(x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiuNYE7nEXRl",
        "outputId": "6e16e66c-5d9a-4655-cb4e-36dab7426f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1024, 3072])\n"
          ]
        }
      ],
      "source": [
        "x = gelu(x)\n",
        "print(x.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3n9JQaSEerI",
        "outputId": "fd9bb659-143b-410d-a716-1f9f816251c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1024, 768])\n"
          ]
        }
      ],
      "source": [
        "x = mlp.c_proj(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038rCL_LGbp7"
      },
      "source": [
        "#### ðŸŽ“ Task 2.03: Shape annotations\n",
        "\n",
        "One of the most common errors in deep learning is a mismatch in tensor dimensions. To avoid this, it is good practice to annotate PyTorch code with shapes. For example, suppose you are given the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iNJjLw-OGbp7"
      },
      "outputs": [],
      "source": [
        "f = nn.Linear(5, 7)\n",
        "x = torch.rand(2, 3, 5)\n",
        "y = f(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7vGTxjjcy_F",
        "outputId": "c74deabb-ac62-42cf-b7b6-5ca56a535b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=5, out_features=7, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Awl0OcQGbp7"
      },
      "source": [
        "The annotation of this code with shapes would look as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uhRiHVKyGbp8"
      },
      "outputs": [],
      "source": [
        "f = nn.Linear(5, 7)\n",
        "# not a tensor variable; needs no annotation\n",
        "\n",
        "x = torch.rand(2, 3, 5)\n",
        "# shape of x: [2, 3, 5]\n",
        "\n",
        "y = f(x)\n",
        "# shape of y: [2, 3, 7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ6J-unZGbp8"
      },
      "source": [
        "Annotate the shapes in the `forward()` method of the feed-forward network. Instead of using actual numbers, refer to dimension sizes by symbolic names such as `n_embd`, `batch_size` (number of samples in a batch of input data) and `seq_len` (length of an input sequence). You can introduce additional names and other notation you find useful. Make your annotations as detailed as you need them to explain how the shapes change from one line to the next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqdkI0_YGbp8"
      },
      "source": [
        "### Causal mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZbXKn0HGbp8"
      },
      "source": [
        "Our next goal is to implement the core of the GPT architecture: the multi-head attention mechanism.\n",
        "\n",
        "Recall that the attention mechanism in the Transformer decoder must be restricted to attending only to previously generated tokens. This type of attention is also called **causal attention**. In practice, we implement it through a masking technique that sets the post-softmax attention weights of future tokens to zero. The following utility function implements such a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T8kdqhsaGbp8"
      },
      "outputs": [],
      "source": [
        "def make_causal_mask(n):\n",
        "    return torch.triu(torch.full((n, n), float(\"-inf\")), diagonal=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbSznvR4Gbp9"
      },
      "source": [
        "#### ðŸŽˆ Task 2.04: Causal mask\n",
        "\n",
        "Have a close look at the following code and run it to see the result. What are the shapes of `x` and `mask`? Given that the shapes are different, why does the addition operation in the last line not raise an error? What is the shape of the result?\n",
        "\n",
        "How does the addition operation implement masking? (Recall that the attention scores are normalised using the softmax function.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9sr9xdNGbp9",
        "outputId": "8e854c6c-ec19-4608-e88b-ea4ed4db21d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0.9325,   -inf,   -inf],\n",
              "          [0.1909, 0.3248,   -inf],\n",
              "          [0.1767, 0.6797, 0.3953]],\n",
              "\n",
              "         [[0.9914,   -inf,   -inf],\n",
              "          [0.0565, 0.4698,   -inf],\n",
              "          [0.7555, 0.7286, 0.3155]]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.rand(1, 2, 3, 3)\n",
        "mask = make_causal_mask(5)\n",
        "x + mask[:3, :3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGvtTD89eoCA",
        "outputId": "494dfada-facd-457e-bb0c-22815ec22486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3, 3])\n",
            "torch.Size([5, 5])\n",
            "torch.Size([1, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(mask.shape)\n",
        "c_mask = x + mask[:3, :3]\n",
        "print(c_mask.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_85BozsSgo2q"
      },
      "source": [
        "When comparing 2 shapes, we look at their dimensions and check for 2 rules:\n",
        "\n",
        "\n",
        "1.   The 2 compared tensors must have the same dimensions size, in this case we have (3, 3) for both x and mask\n",
        "2.   One of them is 1, in here the mask is only shape of 2 so we fill the missing ones with 1 and it will be [1,1,5,5] **(broadcasting)**. However in the last line we selected only the first 3 from the mask so we get [1,1,3,3],  this will help achieving compatibiality with x [1,2,3,3], otherwise we would get an error.\n",
        "\n",
        "Now The final result was [1,2,3,3] because when comparing 2 shapes we always take the maximum size of the two input dimensions being compared.\n",
        "\n",
        "Adding -inf which is the masking is crucial part since it helps minimizing or removing their affect for the prediciton, since we are using softmax, which utilize probability internally, it will see the negative number and will convert it into 0, thus, the model focuses on the current token and all the previous ones since they are part of the input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOv2oUSYGbp9"
      },
      "source": [
        "### Attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eHLIqg0Gbp9"
      },
      "source": [
        "Here is the code for the multi-head attention mechanism:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ngFjO-VxGbp9"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.n_head = config.n_head\n",
        "        self.c_attn = nn.Linear(config.n_embd, config.n_embd * 3)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.register_buffer(\"mask\", make_causal_mask(config.n_ctx), persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Input x:\", x.shape)\n",
        "        batch_size, seq_len, n_embd = x.shape # x.shape: (8, 1024, 768) (B,S,E)\n",
        "        head_embd = n_embd // self.n_head # head_embd = 768 / 12 = 64 (H)\n",
        "        q, k, v = self.c_attn(x).chunk(3, dim=-1) # (8, 1024, 768) for all of them (B,S,E)\n",
        "        print(q.shape, k.shape, v.shape)\n",
        "        q = q.view(batch_size, seq_len, self.n_head, head_embd) # (8, 1024, 12, 64) (B,S,D,H)\n",
        "        k = k.view(batch_size, seq_len, self.n_head, head_embd) # (8, 1024, 12, 64) (B,S,D,H)\n",
        "        v = v.view(batch_size, seq_len, self.n_head, head_embd) # (8, 1024, 12, 64) (B,S,D,H)\n",
        "        print(q.shape, k.shape, v.shape)\n",
        "        q = q.transpose(-2, -3) # (8, 12, 1024, 64) (B,D,S,H)\n",
        "        k = k.transpose(-2, -3) # (8, 12, 1024, 64) (B,D,S,H)\n",
        "        v = v.transpose(-2, -3) # (8, 12, 1024, 64) (B,D,S,H)\n",
        "        print(q.shape, k.shape, v.shape)\n",
        "        x = q @ k.transpose(-1, -2) # (8, 12, 1024, 1024) (B,D,S1,S2)\n",
        "        print('Transpose x: ', x.shape)\n",
        "        x = x / head_embd**0.5 # (8, 12, 1024, 1024) (B,D,S1,S2)\n",
        "        print('x / head_embd**0.5: ', x.shape)\n",
        "        x = x + self.mask[:seq_len, :seq_len] # (8, 12, 1024, 1024) (B,D,S1,S2)\n",
        "        print('x + self.mask[:seq_len, :seq_len] x: ', x.shape)\n",
        "        x = torch.softmax(x, dim=-1) # (8, 12, 1024, 1024) (B,D,S1,S2)\n",
        "        print('softmax x: ', x.shape)\n",
        "        x = x @ v # (8, 12, 1024, 64) (B,D,S,H)\n",
        "        print('x @ v: ', x.shape)\n",
        "        x = x.transpose(-2, -3).contiguous() # (8, 1024, 12, 64) (B,S,D,H)\n",
        "        print('Transpose x: ', x.shape)\n",
        "        x = x.view(batch_size, seq_len, n_embd) #(8, 1024, 768) (B,S,E)\n",
        "        print('x.view: ', x.shape)\n",
        "        x = self.c_proj(x) # (8, 1024, 768) (B,S,E)\n",
        "        print('self.c_proj(x): ', x.shape)\n",
        "        return x # (B,S,E) which returns an output with the same shape as the initial input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e31OZXbs4roh"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    n_vocab: int = 50_257\n",
        "    n_ctx: int = 1024\n",
        "    n_embd: int = 768\n",
        "    n_head: int = 12\n",
        "    n_layer: int = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLY5gx8H2pgL",
        "outputId": "adba3e94-f742-4423-f96f-808285a8b1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x: torch.Size([8, 1024, 768])\n",
            "torch.Size([8, 1024, 768]) torch.Size([8, 1024, 768]) torch.Size([8, 1024, 768])\n",
            "torch.Size([8, 1024, 12, 64]) torch.Size([8, 1024, 12, 64]) torch.Size([8, 1024, 12, 64])\n",
            "torch.Size([8, 12, 1024, 64]) torch.Size([8, 12, 1024, 64]) torch.Size([8, 12, 1024, 64])\n",
            "Transpose x:  torch.Size([8, 12, 1024, 1024])\n",
            "x / head_embd**0.5:  torch.Size([8, 12, 1024, 1024])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([8, 12, 1024, 1024])\n",
            "softmax x:  torch.Size([8, 12, 1024, 1024])\n",
            "x @ v:  torch.Size([8, 12, 1024, 64])\n",
            "Transpose x:  torch.Size([8, 1024, 12, 64])\n",
            "x.view:  torch.Size([8, 1024, 768])\n",
            "self.c_proj(x):  torch.Size([8, 1024, 768])\n"
          ]
        }
      ],
      "source": [
        "attention = Attention(config)\n",
        "batch_size = 8\n",
        "x = torch.randn(batch_size, config.n_ctx, config.n_embd)\n",
        "result = attention(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAjXBEAkGbp-"
      },
      "source": [
        "#### ðŸŽ“ Task 2.05: Multi-head attention\n",
        "\n",
        "Trace the input `x` through the `forward()` method line by line and annotate the shapes of all tensor variables. Identify all lines that rely on broadcasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZg9UY7Gbp-"
      },
      "source": [
        "### Layer normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CExAF7-JGbp-"
      },
      "source": [
        "As mentioned above, the inputs to both the feed-forward network and the multi-head attention mechanism undergo **layer normalisation**. This normalises the inputs to have zero mean and unit variance across the activations. [Ba et al. (2016)](https://doi.org/10.48550/arXiv.1607.06450) introduce two trainable parameters (called $\\gamma$ and $\\beta$ in the paper) that allow the network to learn an appropriate scale and shift for the normalised values.\n",
        "\n",
        "We implement layer normalisation as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bg8s71m9Gbp-"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.g = nn.Parameter(torch.ones(config.n_embd))\n",
        "        self.b = nn.Parameter(torch.zeros(config.n_embd))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        variance = x.var(unbiased=False, dim=-1, keepdim=True)\n",
        "        return self.g * (x - mean) / torch.sqrt(variance + 1e-05) + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4e6zXIMGbp-"
      },
      "source": [
        "#### ðŸŽˆ Task 2.06: Layer normalisation\n",
        "\n",
        "What is the relevance of the `keepdim=True` keyword argument in the `mean()` and `var()` functions? What would happen if we omitted it?\n",
        "\n",
        "What is the relevance of the constant 1e-05? What could happen if we omitted it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASsqnTWQ7_dW"
      },
      "source": [
        "`keepdim  (mean)` is used to tell to keep the last dimension in the output and dont remove it when the dimension is reduced, and this will cause mismatch when we do broadcasting since it will be one dimension less.\n",
        "\n",
        "`keepdim  (var)` is used for the same purpose.\n",
        "\n",
        "`1e-05` By adding this **epsilon** we are preventing the network from crashing since this helps avoiding division on 0. This is done by adding a very small positive number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvFFaovNGbp_"
      },
      "source": [
        "### Decoder block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GcpgRZvGbp_"
      },
      "source": [
        "We now combine the feed-forward network, the multi-head attention mechanism and the layer normalisation into a decoder block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jKZ_KfGdGbp_"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config)\n",
        "        self.attn = Attention(config)\n",
        "        self.ln_2 = LayerNorm(config)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_cDPKr5Gbp_"
      },
      "source": [
        "#### ðŸŽ“ Task 2.07: Pre-norm and post-norm architectures\n",
        "\n",
        "The original Transformer ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)) is a â€œpost-norm architectureâ€, where the normalisation is applied **after** each residual block. In contrast, GPT-2 is a â€œpre-norm architectureâ€, where the normalisation is applied **before**. Find the passage in Section&nbsp;2.3 of [Radford et al. (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) that reports on this modification.\n",
        "\n",
        "[Xiong et al. (2020)](https://arxiv.org/pdf/2002.04745) compare pre-norm and post-norm architectures empirically. Read the abstract of their paper and summarise their main findings. According to these findings, what are the benefits of the pre-norm architecture?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CyU9S-rJEN9"
      },
      "source": [
        " - Layer normalization (Ba et al., 2016) was moved to the input of each sub-block, similar to a pre-activation residual network.\n",
        "\n",
        " - It provides more stablized version since it prevents the gradients from exploding.\n",
        " - It also provides a better perfromace since now the model is more stable even with high learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BatTaRPxGbp_"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBDiKhA3GbqG"
      },
      "source": [
        "We now have almost all components in place to complete the implementation of the GPT-2 model. The only thing  missing are the position embeddings. These simply associate an embedding vector with every position in the context window. To set them up, we first define another utility function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9QDmVF8JGbqG"
      },
      "outputs": [],
      "source": [
        "def make_positions(n):\n",
        "    return torch.arange(n, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3or2yyGGbqH"
      },
      "source": [
        "We then code the complete model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_WpvkcIxGbqH"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.wte = nn.Embedding(config.n_vocab, config.n_embd)\n",
        "        self.wpe = nn.Embedding(config.n_ctx, config.n_embd)\n",
        "        self.h = nn.Sequential(*(Block(config) for _ in range(config.n_layer)))\n",
        "        self.ln_f = LayerNorm(config)\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.n_vocab, bias=False)\n",
        "        self.register_buffer(\"pos\", make_positions(config.n_ctx), persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        wte = self.wte(x)\n",
        "        wpe = self.wpe(self.pos[:seq_len]) # type: ignore\n",
        "        x = wte + wpe\n",
        "        x = self.h(x)\n",
        "        x = self.ln_f(x)\n",
        "        x = self.lm_head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl4UulmLGbqH"
      },
      "source": [
        "#### ðŸŽˆ Task 2.08: Buffers\n",
        "\n",
        "Our implementation registers the vector of positions as a buffer. (Earlier, we also registered the causal mask as a buffer.) Consult the PyTorch documentation to determine the benefits of registering a tensor as a buffer, in contrast to computing it in the `forward()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcipocpF9wwt"
      },
      "source": [
        "There are 2 reasons :\n",
        "- 1_ device management: in this case if we want to move the model from the CPU to GPU, Pytorch does this automatically when it sees the buffer and no error will arise.\n",
        "- 2_ Saving and loading the model based on the last state, this is done also automatically when the Pytorch sees the buffer, in this case non trainable parameters such as (positonal encoding) will be preserved during all the training sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWVWNCETGbqH"
      },
      "source": [
        "#### ðŸŽ“ Task 2.09: Number of trainable parameters\n",
        "\n",
        "The model we have implemented is the smallest one presented by [Radford et al. (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf). But how many trainable parameters exactly does it have? Interestingly, the number originally reported by the authors is wrong! What number did they report?\n",
        "\n",
        "Your task is to write code to compute the number of parameters yourself. This should only take 1â€“3 lines of code. What number do you get when you apply this code to a fresh model instance?\n",
        "\n",
        "[Radford et al. (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) followed the original Transformers paper ([Vaswani et al., 2017](https://doi.org/10.48550/arXiv.1706.03762)) and shared the trainable weights between the token embedding and the final linear layer. Implement this weight sharing strategy. (Hint: This only requires one line of code.) Then, re-compute the number of trainable parameters for the modified model. What number do you get now? How large is the reduction caused by the weight sharing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS2ZgW1BamiA",
        "outputId": "961583f8-9d1f-4f45-ac67-63e6efbe09c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters :163037184\n",
            "Number of trainable parameters for the modified model :124439808\n"
          ]
        }
      ],
      "source": [
        "# The number of paramters is `117m`\n",
        "model = Model(Config())\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters :{total_params}')\n",
        "model.lm_head.weight = model.wte.weight\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters for the modified model :{total_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX52vHixGbqH"
      },
      "source": [
        "## Part 2: Load pre-trained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKPQCJZrGbqI"
      },
      "source": [
        "Now that you have a complete implementation of the GPT-2 model in place, you can instantiate it by loading the pre-trained weights released by OpenAI. These weights were originally provided in the TensorFlow format. For this lab, we have re-packaged them as a single file in NumPyâ€™s `.npz` archive format. We can load it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_R52xp1GbqI",
        "outputId": "a9f61acc-8911-4f53-8a8b-17485245a3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NpzFile 'gpt-2-pretrained.npz' with keys: h0.attn.c_attn.b, h0.attn.c_attn.w, h0.attn.c_proj.b, h0.attn.c_proj.w, h0.ln_1.b...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "pretrained = np.load(\"gpt-2-pretrained.npz\")\n",
        "print(pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WORKgzf5GbqI"
      },
      "source": [
        "The result `pretrained` is a dictionary mapping names to NumPy arrays. When you print the names, you will see that they correspond to the attributes of our network modules, even though the names differ. For example, the array `h0.attn.c_attn.b` holds the biases (`b`) of the `c_attn` linear layer in the attention mechanism (`attn`) of the first transformer block (`h0`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G5jEZb2GbqI"
      },
      "source": [
        "#### ðŸŽ“ Task 2.10: Load pre-trained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi1hzO3sGbqI"
      },
      "source": [
        "Create a model from the pre-trained weights. To do this, you need to instantiate a fresh model and write the contents of each array from the `npz` archive with the pre-trained weights into the corresponding tensor. To make this a bit easier, here is a utility function that copies data from a NumPy array `source` to a PyTorch tensor `target`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtSHdHUxtfw2",
        "outputId": "bc4f6759-9b9c-49f7-cf70-3d11b3295dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h0.attn.c_attn.b\n",
            "h0.attn.c_attn.w\n",
            "h0.attn.c_proj.b\n",
            "h0.attn.c_proj.w\n",
            "h0.ln_1.b\n",
            "h0.ln_1.g\n",
            "h0.ln_2.b\n",
            "h0.ln_2.g\n",
            "h0.mlp.c_fc.b\n",
            "h0.mlp.c_fc.w\n",
            "h0.mlp.c_proj.b\n",
            "h0.mlp.c_proj.w\n",
            "h1.attn.c_attn.b\n",
            "h1.attn.c_attn.w\n",
            "h1.attn.c_proj.b\n",
            "h1.attn.c_proj.w\n",
            "h1.ln_1.b\n",
            "h1.ln_1.g\n",
            "h1.ln_2.b\n",
            "h1.ln_2.g\n",
            "h1.mlp.c_fc.b\n",
            "h1.mlp.c_fc.w\n",
            "h1.mlp.c_proj.b\n",
            "h1.mlp.c_proj.w\n",
            "h10.attn.c_attn.b\n",
            "h10.attn.c_attn.w\n",
            "h10.attn.c_proj.b\n",
            "h10.attn.c_proj.w\n",
            "h10.ln_1.b\n",
            "h10.ln_1.g\n",
            "h10.ln_2.b\n",
            "h10.ln_2.g\n",
            "h10.mlp.c_fc.b\n",
            "h10.mlp.c_fc.w\n",
            "h10.mlp.c_proj.b\n",
            "h10.mlp.c_proj.w\n",
            "h11.attn.c_attn.b\n",
            "h11.attn.c_attn.w\n",
            "h11.attn.c_proj.b\n",
            "h11.attn.c_proj.w\n",
            "h11.ln_1.b\n",
            "h11.ln_1.g\n",
            "h11.ln_2.b\n",
            "h11.ln_2.g\n",
            "h11.mlp.c_fc.b\n",
            "h11.mlp.c_fc.w\n",
            "h11.mlp.c_proj.b\n",
            "h11.mlp.c_proj.w\n",
            "h2.attn.c_attn.b\n",
            "h2.attn.c_attn.w\n",
            "h2.attn.c_proj.b\n",
            "h2.attn.c_proj.w\n",
            "h2.ln_1.b\n",
            "h2.ln_1.g\n",
            "h2.ln_2.b\n",
            "h2.ln_2.g\n",
            "h2.mlp.c_fc.b\n",
            "h2.mlp.c_fc.w\n",
            "h2.mlp.c_proj.b\n",
            "h2.mlp.c_proj.w\n",
            "h3.attn.c_attn.b\n",
            "h3.attn.c_attn.w\n",
            "h3.attn.c_proj.b\n",
            "h3.attn.c_proj.w\n",
            "h3.ln_1.b\n",
            "h3.ln_1.g\n",
            "h3.ln_2.b\n",
            "h3.ln_2.g\n",
            "h3.mlp.c_fc.b\n",
            "h3.mlp.c_fc.w\n",
            "h3.mlp.c_proj.b\n",
            "h3.mlp.c_proj.w\n",
            "h4.attn.c_attn.b\n",
            "h4.attn.c_attn.w\n",
            "h4.attn.c_proj.b\n",
            "h4.attn.c_proj.w\n",
            "h4.ln_1.b\n",
            "h4.ln_1.g\n",
            "h4.ln_2.b\n",
            "h4.ln_2.g\n",
            "h4.mlp.c_fc.b\n",
            "h4.mlp.c_fc.w\n",
            "h4.mlp.c_proj.b\n",
            "h4.mlp.c_proj.w\n",
            "h5.attn.c_attn.b\n",
            "h5.attn.c_attn.w\n",
            "h5.attn.c_proj.b\n",
            "h5.attn.c_proj.w\n",
            "h5.ln_1.b\n",
            "h5.ln_1.g\n",
            "h5.ln_2.b\n",
            "h5.ln_2.g\n",
            "h5.mlp.c_fc.b\n",
            "h5.mlp.c_fc.w\n",
            "h5.mlp.c_proj.b\n",
            "h5.mlp.c_proj.w\n",
            "h6.attn.c_attn.b\n",
            "h6.attn.c_attn.w\n",
            "h6.attn.c_proj.b\n",
            "h6.attn.c_proj.w\n",
            "h6.ln_1.b\n",
            "h6.ln_1.g\n",
            "h6.ln_2.b\n",
            "h6.ln_2.g\n",
            "h6.mlp.c_fc.b\n",
            "h6.mlp.c_fc.w\n",
            "h6.mlp.c_proj.b\n",
            "h6.mlp.c_proj.w\n",
            "h7.attn.c_attn.b\n",
            "h7.attn.c_attn.w\n",
            "h7.attn.c_proj.b\n",
            "h7.attn.c_proj.w\n",
            "h7.ln_1.b\n",
            "h7.ln_1.g\n",
            "h7.ln_2.b\n",
            "h7.ln_2.g\n",
            "h7.mlp.c_fc.b\n",
            "h7.mlp.c_fc.w\n",
            "h7.mlp.c_proj.b\n",
            "h7.mlp.c_proj.w\n",
            "h8.attn.c_attn.b\n",
            "h8.attn.c_attn.w\n",
            "h8.attn.c_proj.b\n",
            "h8.attn.c_proj.w\n",
            "h8.ln_1.b\n",
            "h8.ln_1.g\n",
            "h8.ln_2.b\n",
            "h8.ln_2.g\n",
            "h8.mlp.c_fc.b\n",
            "h8.mlp.c_fc.w\n",
            "h8.mlp.c_proj.b\n",
            "h8.mlp.c_proj.w\n",
            "h9.attn.c_attn.b\n",
            "h9.attn.c_attn.w\n",
            "h9.attn.c_proj.b\n",
            "h9.attn.c_proj.w\n",
            "h9.ln_1.b\n",
            "h9.ln_1.g\n",
            "h9.ln_2.b\n",
            "h9.ln_2.g\n",
            "h9.mlp.c_fc.b\n",
            "h9.mlp.c_fc.w\n",
            "h9.mlp.c_proj.b\n",
            "h9.mlp.c_proj.w\n",
            "ln_f.b\n",
            "ln_f.g\n",
            "wpe\n",
            "wte\n"
          ]
        }
      ],
      "source": [
        "for t in pretrained:\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z6uU6HvGbqJ"
      },
      "outputs": [],
      "source": [
        "def copy_weights(source: np.ndarray, target: torch.Tensor):\n",
        "    assert source.shape == target.shape\n",
        "    with torch.no_grad():\n",
        "        target.copy_(torch.tensor(source, dtype=torch.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0iiPR_NGbqJ"
      },
      "source": [
        "You can start from this skeleton code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSwN7s2zGbqJ"
      },
      "outputs": [],
      "source": [
        "def from_pretrained() -> Model:\n",
        "    model = Model(Config())\n",
        "    pretrained = np.load(\"gpt-2-pretrained.npz\")\n",
        "    copy_weights(pretrained['wte'], model.wte.weight)\n",
        "    copy_weights(pretrained['wpe'], model.wpe.weight)\n",
        "    copy_weights(pretrained['ln_f.b'], model.ln_f.b)\n",
        "    copy_weights(pretrained['ln_f.g'], model.ln_f.g)\n",
        "    copy_weights(pretrained['wte'], model.lm_head.weight)\n",
        "    for i in range(config.n_layer):\n",
        "      copy_weights(pretrained[f'h{i}.ln_1.b'], model.h[i].ln_1.b)\n",
        "      copy_weights(pretrained[f'h{i}.ln_1.g'], model.h[i].ln_1.g)\n",
        "      copy_weights(pretrained[f'h{i}.ln_2.b'], model.h[i].ln_2.b)\n",
        "      copy_weights(pretrained[f'h{i}.ln_2.g'], model.h[i].ln_2.g)\n",
        "      copy_weights(pretrained[f'h{i}.attn.c_attn.w'].T, model.h[i].attn.c_attn.weight)\n",
        "      copy_weights(pretrained[f'h{i}.attn.c_attn.b'], model.h[i].attn.c_attn.bias)\n",
        "      copy_weights(pretrained[f'h{i}.attn.c_proj.w'].T, model.h[i].attn.c_proj.weight)\n",
        "      copy_weights(pretrained[f'h{i}.attn.c_proj.b'], model.h[i].attn.c_proj.bias)\n",
        "\n",
        "      copy_weights(pretrained[f'h{i}.mlp.c_fc.w'].T, model.h[i].mlp.c_fc.weight)\n",
        "      copy_weights(pretrained[f'h{i}.mlp.c_fc.b'], model.h[i].mlp.c_fc.bias)\n",
        "      copy_weights(pretrained[f'h{i}.mlp.c_proj.w'].T, model.h[i].mlp.c_proj.weight)\n",
        "      copy_weights(pretrained[f'h{i}.mlp.c_proj.b'], model.h[i].mlp.c_proj.bias)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRw5pY8jGbqJ"
      },
      "source": [
        "**Important:** One technical detail to note is that PyTorch stores the weights of linear layers in a transposed form. For example, a linear layer created as `nn.Linear(2, 3)` has a weight matrix of shape [3, 2]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVXc-mImGbqJ"
      },
      "source": [
        "## Part 3: Put the model to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8zQQLBQGbqK"
      },
      "source": [
        "In the third and final part of this lab, you will use the pre-trained model to generate text and evaluate it on a standard benchmark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0gSxXcLGbqK"
      },
      "source": [
        "### Sampling-based text generation\n",
        "\n",
        "The easiest way to generate text with a language model is by using a **greedy approach**. This method works by creating text one token at a time. At each step, the model takes the previously generated text (called the **context**) as input and adds the token with the highest output logit as a new token. The code in the next cell defines a function `generate()` that forms the core of a greedy generator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htoOy71aGbqK"
      },
      "outputs": [],
      "source": [
        "def generate(model, context, context_size=1024, n_tokens=20):\n",
        "    for _ in range(n_tokens):\n",
        "        context = context[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(context)[:, -1, :]\n",
        "        next_idx = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "        context = torch.cat([context, next_idx], dim=-1)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wst1MSY-GbqK"
      },
      "source": [
        "To use this function with an actual text input, you need a tokeniser to first encode the text into a vector of token IDs, and later decode the generated `context` into new text. The reference implementation of the GPT-2 tokeniser is in the library `tiktoken`. The code in the next cell sets up the tokeniser, loads the pretrained model from Task&nbsp;2.10, and then defines a helper function that handles the encoding and decoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBggKvqSGbqK"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "model = from_pretrained()\n",
        "\n",
        "\n",
        "def generate_helper(text, context_size=1024, n_tokens=20):\n",
        "    context = torch.tensor([tokenizer.encode(text)], dtype=torch.long)\n",
        "    context = generate(model, context, context_size=context_size, n_tokens=n_tokens)\n",
        "    return tokenizer.decode(context[0].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj2xV8uFGbqL"
      },
      "source": [
        ":You can use this helper function to generate text as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lGwHfGbLGbqL",
        "outputId": "877d491e-8ce3-44df-d69a-c48db5424a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LinkÃ¶ping University is a research institute in the Netherlands.\\n\\nThe research was funded by the European Union's European Research\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_helper(\"LinkÃ¶ping University is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDYWTS_sGbqL"
      },
      "source": [
        "**Tip:** If you did not manage to complete Task&nbsp;2.10, you can still work on this task by using a pretrained GPT-2 model from [Hugging Face](https://huggingface.co/openai-community/gpt2). The next code cell shows how you would instantiate this model. Note that you may have to first install the `transformers` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nh3TnL5GbqL"
      },
      "outputs": [],
      "source": [
        "# from transformers import GPT2LMHeadModel\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "# logits = model(context).logits[:, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM3_cDr0GbqM"
      },
      "source": [
        "#### ðŸŽ“ Task 2.11: Sampling-based text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQdO8AXGbqM"
      },
      "source": [
        " The greedy approach to text generation is not very interesting for practical applications because it always chooses the most likely token, leading to predictable and less creative results. Your task is to modify the code for the `generate()` function to use a **sampling-based approach** instead. In this approach, the next token is chosen randomly based on the probabilities assigned by the model (softmax-normalised logits), treating them as a categorical distribution over the token vocabulary. Additionally, your code should include two common techniques to improve sampling:\n",
        "\n",
        " * **temperature scaling**, which lets the user control the randomness of the sampling\n",
        " * **top-$k$ sampling**, which limits the sampling to the top-$k$ most likely tokens, ignoring less probable ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO2UUBae96EE"
      },
      "outputs": [],
      "source": [
        "def generate(model, context, context_size=1024, n_tokens=20, temp=1, top_k=0):\n",
        "    for _ in range(n_tokens):\n",
        "        context = context[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = (model(context)[:, -1, :])/temp\n",
        "        if top_k > 0:\n",
        "          # In here we wanted to find the index of the top k values\n",
        "          top_k_v, _ = torch.topk(logits, k=top_k, dim=-1)\n",
        "          smallest_v = top_k_v[...,-1].unsqueeze(-1)\n",
        "          # In here are are mask all the logits below the smallest k value by setting it negative inf to not affect the prediciton\n",
        "          logits = torch.where(logits < smallest_v, torch.tensor(float('-inf')), logits)\n",
        "        prob = torch.softmax(logits,dim=-1)\n",
        "        next_index = torch.multinomial(prob, num_samples=1)\n",
        "        context = torch.cat([context, next_index], dim=-1)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itVOCykoDNcx"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "model = from_pretrained()\n",
        "\n",
        "\n",
        "def generate_helper(text, context_size=1024, n_tokens=20):\n",
        "    context = torch.tensor([tokenizer.encode(text)], dtype=torch.long)\n",
        "    context = generate(model, context, context_size=context_size, n_tokens=n_tokens)\n",
        "    return tokenizer.decode(context[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IKY0lhThDUnH",
        "outputId": "69f09bc8-c431-4a49-a0cd-86905c601b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 768]) torch.Size([1, 5, 768]) torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64]) torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64]) torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 12, 5, 5])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 5, 5])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 5, 5])\n",
            "softmax x:  torch.Size([1, 12, 5, 5])\n",
            "x @ v:  torch.Size([1, 12, 5, 64])\n",
            "Transpose x:  torch.Size([1, 5, 12, 64])\n",
            "x.view:  torch.Size([1, 5, 768])\n",
            "self.c_proj(x):  torch.Size([1, 5, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 768]) torch.Size([1, 6, 768]) torch.Size([1, 6, 768])\n",
            "torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64]) torch.Size([1, 6, 12, 64])\n",
            "torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64]) torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 12, 6, 6])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 6, 6])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 6, 6])\n",
            "softmax x:  torch.Size([1, 12, 6, 6])\n",
            "x @ v:  torch.Size([1, 12, 6, 64])\n",
            "Transpose x:  torch.Size([1, 6, 12, 64])\n",
            "x.view:  torch.Size([1, 6, 768])\n",
            "self.c_proj(x):  torch.Size([1, 6, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 7, 768]) torch.Size([1, 7, 768])\n",
            "torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64]) torch.Size([1, 7, 12, 64])\n",
            "torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64]) torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 12, 7, 7])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 7, 7])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 7, 7])\n",
            "softmax x:  torch.Size([1, 12, 7, 7])\n",
            "x @ v:  torch.Size([1, 12, 7, 64])\n",
            "Transpose x:  torch.Size([1, 7, 12, 64])\n",
            "x.view:  torch.Size([1, 7, 768])\n",
            "self.c_proj(x):  torch.Size([1, 7, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 768]) torch.Size([1, 8, 768]) torch.Size([1, 8, 768])\n",
            "torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64]) torch.Size([1, 8, 12, 64])\n",
            "torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64]) torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 12, 8, 8])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 8, 8])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 8, 8])\n",
            "softmax x:  torch.Size([1, 12, 8, 8])\n",
            "x @ v:  torch.Size([1, 12, 8, 64])\n",
            "Transpose x:  torch.Size([1, 8, 12, 64])\n",
            "x.view:  torch.Size([1, 8, 768])\n",
            "self.c_proj(x):  torch.Size([1, 8, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 768]) torch.Size([1, 9, 768]) torch.Size([1, 9, 768])\n",
            "torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64]) torch.Size([1, 9, 12, 64])\n",
            "torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64]) torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 12, 9, 9])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 9, 9])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 9, 9])\n",
            "softmax x:  torch.Size([1, 12, 9, 9])\n",
            "x @ v:  torch.Size([1, 12, 9, 64])\n",
            "Transpose x:  torch.Size([1, 9, 12, 64])\n",
            "x.view:  torch.Size([1, 9, 768])\n",
            "self.c_proj(x):  torch.Size([1, 9, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 768]) torch.Size([1, 10, 768]) torch.Size([1, 10, 768])\n",
            "torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64]) torch.Size([1, 10, 12, 64])\n",
            "torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64]) torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 12, 10, 10])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 10, 10])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 10, 10])\n",
            "softmax x:  torch.Size([1, 12, 10, 10])\n",
            "x @ v:  torch.Size([1, 12, 10, 64])\n",
            "Transpose x:  torch.Size([1, 10, 12, 64])\n",
            "x.view:  torch.Size([1, 10, 768])\n",
            "self.c_proj(x):  torch.Size([1, 10, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 768]) torch.Size([1, 11, 768]) torch.Size([1, 11, 768])\n",
            "torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64]) torch.Size([1, 11, 12, 64])\n",
            "torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64]) torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 12, 11, 11])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 11, 11])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 11, 11])\n",
            "softmax x:  torch.Size([1, 12, 11, 11])\n",
            "x @ v:  torch.Size([1, 12, 11, 64])\n",
            "Transpose x:  torch.Size([1, 11, 12, 64])\n",
            "x.view:  torch.Size([1, 11, 768])\n",
            "self.c_proj(x):  torch.Size([1, 11, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 768]) torch.Size([1, 12, 768]) torch.Size([1, 12, 768])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64]) torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 12])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 12, 12])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 12, 12])\n",
            "softmax x:  torch.Size([1, 12, 12, 12])\n",
            "x @ v:  torch.Size([1, 12, 12, 64])\n",
            "Transpose x:  torch.Size([1, 12, 12, 64])\n",
            "x.view:  torch.Size([1, 12, 768])\n",
            "self.c_proj(x):  torch.Size([1, 12, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 768]) torch.Size([1, 13, 768]) torch.Size([1, 13, 768])\n",
            "torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64]) torch.Size([1, 13, 12, 64])\n",
            "torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64]) torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 12, 13, 13])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 13, 13])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 13, 13])\n",
            "softmax x:  torch.Size([1, 12, 13, 13])\n",
            "x @ v:  torch.Size([1, 12, 13, 64])\n",
            "Transpose x:  torch.Size([1, 13, 12, 64])\n",
            "x.view:  torch.Size([1, 13, 768])\n",
            "self.c_proj(x):  torch.Size([1, 13, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 768]) torch.Size([1, 14, 768]) torch.Size([1, 14, 768])\n",
            "torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64]) torch.Size([1, 14, 12, 64])\n",
            "torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64]) torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 12, 14, 14])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 14, 14])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 14, 14])\n",
            "softmax x:  torch.Size([1, 12, 14, 14])\n",
            "x @ v:  torch.Size([1, 12, 14, 64])\n",
            "Transpose x:  torch.Size([1, 14, 12, 64])\n",
            "x.view:  torch.Size([1, 14, 768])\n",
            "self.c_proj(x):  torch.Size([1, 14, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 768]) torch.Size([1, 15, 768]) torch.Size([1, 15, 768])\n",
            "torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64]) torch.Size([1, 15, 12, 64])\n",
            "torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64]) torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 12, 15, 15])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 15, 15])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 15, 15])\n",
            "softmax x:  torch.Size([1, 12, 15, 15])\n",
            "x @ v:  torch.Size([1, 12, 15, 64])\n",
            "Transpose x:  torch.Size([1, 15, 12, 64])\n",
            "x.view:  torch.Size([1, 15, 768])\n",
            "self.c_proj(x):  torch.Size([1, 15, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 768]) torch.Size([1, 16, 768]) torch.Size([1, 16, 768])\n",
            "torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64]) torch.Size([1, 16, 12, 64])\n",
            "torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64]) torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 12, 16, 16])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 16, 16])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 16, 16])\n",
            "softmax x:  torch.Size([1, 12, 16, 16])\n",
            "x @ v:  torch.Size([1, 12, 16, 64])\n",
            "Transpose x:  torch.Size([1, 16, 12, 64])\n",
            "x.view:  torch.Size([1, 16, 768])\n",
            "self.c_proj(x):  torch.Size([1, 16, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 768]) torch.Size([1, 17, 768]) torch.Size([1, 17, 768])\n",
            "torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64]) torch.Size([1, 17, 12, 64])\n",
            "torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64]) torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 12, 17, 17])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 17, 17])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 17, 17])\n",
            "softmax x:  torch.Size([1, 12, 17, 17])\n",
            "x @ v:  torch.Size([1, 12, 17, 64])\n",
            "Transpose x:  torch.Size([1, 17, 12, 64])\n",
            "x.view:  torch.Size([1, 17, 768])\n",
            "self.c_proj(x):  torch.Size([1, 17, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 768]) torch.Size([1, 18, 768]) torch.Size([1, 18, 768])\n",
            "torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64]) torch.Size([1, 18, 12, 64])\n",
            "torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64]) torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 12, 18, 18])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 18, 18])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 18, 18])\n",
            "softmax x:  torch.Size([1, 12, 18, 18])\n",
            "x @ v:  torch.Size([1, 12, 18, 64])\n",
            "Transpose x:  torch.Size([1, 18, 12, 64])\n",
            "x.view:  torch.Size([1, 18, 768])\n",
            "self.c_proj(x):  torch.Size([1, 18, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 768]) torch.Size([1, 19, 768]) torch.Size([1, 19, 768])\n",
            "torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64]) torch.Size([1, 19, 12, 64])\n",
            "torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64]) torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 12, 19, 19])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 19, 19])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 19, 19])\n",
            "softmax x:  torch.Size([1, 12, 19, 19])\n",
            "x @ v:  torch.Size([1, 12, 19, 64])\n",
            "Transpose x:  torch.Size([1, 19, 12, 64])\n",
            "x.view:  torch.Size([1, 19, 768])\n",
            "self.c_proj(x):  torch.Size([1, 19, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 768]) torch.Size([1, 20, 768]) torch.Size([1, 20, 768])\n",
            "torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64]) torch.Size([1, 20, 12, 64])\n",
            "torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64]) torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 12, 20, 20])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 20, 20])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 20, 20])\n",
            "softmax x:  torch.Size([1, 12, 20, 20])\n",
            "x @ v:  torch.Size([1, 12, 20, 64])\n",
            "Transpose x:  torch.Size([1, 20, 12, 64])\n",
            "x.view:  torch.Size([1, 20, 768])\n",
            "self.c_proj(x):  torch.Size([1, 20, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 768]) torch.Size([1, 21, 768]) torch.Size([1, 21, 768])\n",
            "torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64]) torch.Size([1, 21, 12, 64])\n",
            "torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64]) torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 12, 21, 21])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 21, 21])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 21, 21])\n",
            "softmax x:  torch.Size([1, 12, 21, 21])\n",
            "x @ v:  torch.Size([1, 12, 21, 64])\n",
            "Transpose x:  torch.Size([1, 21, 12, 64])\n",
            "x.view:  torch.Size([1, 21, 768])\n",
            "self.c_proj(x):  torch.Size([1, 21, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 768]) torch.Size([1, 22, 768]) torch.Size([1, 22, 768])\n",
            "torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64]) torch.Size([1, 22, 12, 64])\n",
            "torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64]) torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 12, 22, 22])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 22, 22])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 22, 22])\n",
            "softmax x:  torch.Size([1, 12, 22, 22])\n",
            "x @ v:  torch.Size([1, 12, 22, 64])\n",
            "Transpose x:  torch.Size([1, 22, 12, 64])\n",
            "x.view:  torch.Size([1, 22, 768])\n",
            "self.c_proj(x):  torch.Size([1, 22, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 768]) torch.Size([1, 23, 768]) torch.Size([1, 23, 768])\n",
            "torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64]) torch.Size([1, 23, 12, 64])\n",
            "torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64]) torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 12, 23, 23])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 23, 23])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 23, 23])\n",
            "softmax x:  torch.Size([1, 12, 23, 23])\n",
            "x @ v:  torch.Size([1, 12, 23, 64])\n",
            "Transpose x:  torch.Size([1, 23, 12, 64])\n",
            "x.view:  torch.Size([1, 23, 768])\n",
            "self.c_proj(x):  torch.Size([1, 23, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'LinkÃ¶ping University is still impressing international media this week with its discovery that Neanderthal bones from Pembroke P'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_helper(\"LinkÃ¶ping University is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITD0cAUaGbqM"
      },
      "source": [
        "### Evaluating the pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E3-Dt9RGbqM"
      },
      "source": [
        "If you have experimented with your pretrained GPT-2 model, you will have noticed that its ability to generate useful text is somewhat limited. By todayâ€™s standards, GPT-2 is a small model with modest capabilities. However, it can still be helpful for certain tasks, such as text autocompletion, generating filler text, or answering simple questions. To rigourosly evaluate language models, researchers often use standard benchmark datasets. Creating these benchmarks is a discipline of its own, and they tend to become increasingly challenging as models continue to improve.\n",
        "\n",
        "In the final task of this lab, you will evaluate GPT-2â€™s performance on a small subset of the [HellaSwag dataset](https://rowanzellers.com/hellaswag/), which was published in the same year as GPT-2 itself (2019). HellaSwag is designed to test a modelâ€™s ability to perform commonsense reasoning in challenging contexts. Unlike simpler benchmarks, HellaSwag presents scenarios where the correct text completion depends on semantic relationships between events and on world knowledge. This makes it a good choice for assessing the ability of language models to go beyond surface-level patterns and produce meaningful, context-aware predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPkbd8WNGbqM"
      },
      "source": [
        "#### ðŸŽ“ Task 2.12: Evaluating the pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMJnFho5GbqM"
      },
      "source": [
        "Read the [HellaSwag website](https://rowanzellers.com/hellaswag/) to get some background on the benchmark. How does a sample from the dataset look like? What is an expected prediction? How does the benchmark allow us to score models? What is the random baseline? What is the human performance reported on the task?\n",
        "\n",
        "The next cell contains code for evaluating your pretrained model on a small sample from HellaSwag. You will also need a tokenizer. The HellaSwag subset is in the file `hellaswag-mini.jsonl`. Inspect that file to understand the format. Next, read the code and explain how it works. Specifically, how does the code compute the score of individual endings? In the call to `cross_entropy()`, why are the tensors sliced in this specific way?\n",
        "\n",
        "Finally, what overall score does the pretrained GPT-2 model get on this benchmark? How does that score compare to the random baseline and the human performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIGTOtupGbqN",
        "outputId": "ed72c248-3308-462b-b805-5d1e413c781b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 768]) torch.Size([1, 116, 768]) torch.Size([1, 116, 768])\n",
            "torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64]) torch.Size([1, 116, 12, 64])\n",
            "torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64]) torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 12, 116, 116])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 116, 116])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 116, 116])\n",
            "softmax x:  torch.Size([1, 12, 116, 116])\n",
            "x @ v:  torch.Size([1, 12, 116, 64])\n",
            "Transpose x:  torch.Size([1, 116, 12, 64])\n",
            "x.view:  torch.Size([1, 116, 768])\n",
            "self.c_proj(x):  torch.Size([1, 116, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 768]) torch.Size([1, 106, 768]) torch.Size([1, 106, 768])\n",
            "torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64]) torch.Size([1, 106, 12, 64])\n",
            "torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64]) torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 12, 106, 106])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 106, 106])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 106, 106])\n",
            "softmax x:  torch.Size([1, 12, 106, 106])\n",
            "x @ v:  torch.Size([1, 12, 106, 64])\n",
            "Transpose x:  torch.Size([1, 106, 12, 64])\n",
            "x.view:  torch.Size([1, 106, 768])\n",
            "self.c_proj(x):  torch.Size([1, 106, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 768]) torch.Size([1, 99, 768]) torch.Size([1, 99, 768])\n",
            "torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64]) torch.Size([1, 99, 12, 64])\n",
            "torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64]) torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 12, 99, 99])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 99, 99])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 99, 99])\n",
            "softmax x:  torch.Size([1, 12, 99, 99])\n",
            "x @ v:  torch.Size([1, 12, 99, 64])\n",
            "Transpose x:  torch.Size([1, 99, 12, 64])\n",
            "x.view:  torch.Size([1, 99, 768])\n",
            "self.c_proj(x):  torch.Size([1, 99, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 768]) torch.Size([1, 108, 768]) torch.Size([1, 108, 768])\n",
            "torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64]) torch.Size([1, 108, 12, 64])\n",
            "torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64]) torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 12, 108, 108])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 108, 108])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 108, 108])\n",
            "softmax x:  torch.Size([1, 12, 108, 108])\n",
            "x @ v:  torch.Size([1, 12, 108, 64])\n",
            "Transpose x:  torch.Size([1, 108, 12, 64])\n",
            "x.view:  torch.Size([1, 108, 768])\n",
            "self.c_proj(x):  torch.Size([1, 108, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 768]) torch.Size([1, 127, 768]) torch.Size([1, 127, 768])\n",
            "torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64]) torch.Size([1, 127, 12, 64])\n",
            "torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64]) torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 12, 127, 127])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 127, 127])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 127, 127])\n",
            "softmax x:  torch.Size([1, 12, 127, 127])\n",
            "x @ v:  torch.Size([1, 12, 127, 64])\n",
            "Transpose x:  torch.Size([1, 127, 12, 64])\n",
            "x.view:  torch.Size([1, 127, 768])\n",
            "self.c_proj(x):  torch.Size([1, 127, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 768]) torch.Size([1, 107, 768]) torch.Size([1, 107, 768])\n",
            "torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64]) torch.Size([1, 107, 12, 64])\n",
            "torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64]) torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 12, 107, 107])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 107, 107])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 107, 107])\n",
            "softmax x:  torch.Size([1, 12, 107, 107])\n",
            "x @ v:  torch.Size([1, 12, 107, 64])\n",
            "Transpose x:  torch.Size([1, 107, 12, 64])\n",
            "x.view:  torch.Size([1, 107, 768])\n",
            "self.c_proj(x):  torch.Size([1, 107, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 768]) torch.Size([1, 29, 768]) torch.Size([1, 29, 768])\n",
            "torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64]) torch.Size([1, 29, 12, 64])\n",
            "torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64]) torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 12, 29, 29])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 29, 29])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 29, 29])\n",
            "softmax x:  torch.Size([1, 12, 29, 29])\n",
            "x @ v:  torch.Size([1, 12, 29, 64])\n",
            "Transpose x:  torch.Size([1, 29, 12, 64])\n",
            "x.view:  torch.Size([1, 29, 768])\n",
            "self.c_proj(x):  torch.Size([1, 29, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 768]) torch.Size([1, 24, 768]) torch.Size([1, 24, 768])\n",
            "torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64]) torch.Size([1, 24, 12, 64])\n",
            "torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64]) torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 12, 24, 24])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 24, 24])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 24, 24])\n",
            "softmax x:  torch.Size([1, 12, 24, 24])\n",
            "x @ v:  torch.Size([1, 12, 24, 64])\n",
            "Transpose x:  torch.Size([1, 24, 12, 64])\n",
            "x.view:  torch.Size([1, 24, 768])\n",
            "self.c_proj(x):  torch.Size([1, 24, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 768]) torch.Size([1, 27, 768]) torch.Size([1, 27, 768])\n",
            "torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64]) torch.Size([1, 27, 12, 64])\n",
            "torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64]) torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 12, 27, 27])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 27, 27])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 27, 27])\n",
            "softmax x:  torch.Size([1, 12, 27, 27])\n",
            "x @ v:  torch.Size([1, 12, 27, 64])\n",
            "Transpose x:  torch.Size([1, 27, 12, 64])\n",
            "x.view:  torch.Size([1, 27, 768])\n",
            "self.c_proj(x):  torch.Size([1, 27, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 768]) torch.Size([1, 55, 768]) torch.Size([1, 55, 768])\n",
            "torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64]) torch.Size([1, 55, 12, 64])\n",
            "torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64]) torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 12, 55, 55])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 55, 55])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 55, 55])\n",
            "softmax x:  torch.Size([1, 12, 55, 55])\n",
            "x @ v:  torch.Size([1, 12, 55, 64])\n",
            "Transpose x:  torch.Size([1, 55, 12, 64])\n",
            "x.view:  torch.Size([1, 55, 768])\n",
            "self.c_proj(x):  torch.Size([1, 55, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 768]) torch.Size([1, 57, 768]) torch.Size([1, 57, 768])\n",
            "torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64]) torch.Size([1, 57, 12, 64])\n",
            "torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64]) torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 12, 57, 57])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 57, 57])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 57, 57])\n",
            "softmax x:  torch.Size([1, 12, 57, 57])\n",
            "x @ v:  torch.Size([1, 12, 57, 64])\n",
            "Transpose x:  torch.Size([1, 57, 12, 64])\n",
            "x.view:  torch.Size([1, 57, 768])\n",
            "self.c_proj(x):  torch.Size([1, 57, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 768]) torch.Size([1, 54, 768]) torch.Size([1, 54, 768])\n",
            "torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64]) torch.Size([1, 54, 12, 64])\n",
            "torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64]) torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 12, 54, 54])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 54, 54])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 54, 54])\n",
            "softmax x:  torch.Size([1, 12, 54, 54])\n",
            "x @ v:  torch.Size([1, 12, 54, 64])\n",
            "Transpose x:  torch.Size([1, 54, 12, 64])\n",
            "x.view:  torch.Size([1, 54, 768])\n",
            "self.c_proj(x):  torch.Size([1, 54, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 768]) torch.Size([1, 100, 768]) torch.Size([1, 100, 768])\n",
            "torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64]) torch.Size([1, 100, 12, 64])\n",
            "torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64]) torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 12, 100, 100])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 100, 100])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 100, 100])\n",
            "softmax x:  torch.Size([1, 12, 100, 100])\n",
            "x @ v:  torch.Size([1, 12, 100, 64])\n",
            "Transpose x:  torch.Size([1, 100, 12, 64])\n",
            "x.view:  torch.Size([1, 100, 768])\n",
            "self.c_proj(x):  torch.Size([1, 100, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 768]) torch.Size([1, 110, 768]) torch.Size([1, 110, 768])\n",
            "torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64]) torch.Size([1, 110, 12, 64])\n",
            "torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64]) torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 12, 110, 110])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 110, 110])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 110, 110])\n",
            "softmax x:  torch.Size([1, 12, 110, 110])\n",
            "x @ v:  torch.Size([1, 12, 110, 64])\n",
            "Transpose x:  torch.Size([1, 110, 12, 64])\n",
            "x.view:  torch.Size([1, 110, 768])\n",
            "self.c_proj(x):  torch.Size([1, 110, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 768]) torch.Size([1, 94, 768]) torch.Size([1, 94, 768])\n",
            "torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64]) torch.Size([1, 94, 12, 64])\n",
            "torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64]) torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 12, 94, 94])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 94, 94])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 94, 94])\n",
            "softmax x:  torch.Size([1, 12, 94, 94])\n",
            "x @ v:  torch.Size([1, 12, 94, 64])\n",
            "Transpose x:  torch.Size([1, 94, 12, 64])\n",
            "x.view:  torch.Size([1, 94, 768])\n",
            "self.c_proj(x):  torch.Size([1, 94, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 768]) torch.Size([1, 95, 768]) torch.Size([1, 95, 768])\n",
            "torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64]) torch.Size([1, 95, 12, 64])\n",
            "torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64]) torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 12, 95, 95])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 95, 95])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 95, 95])\n",
            "softmax x:  torch.Size([1, 12, 95, 95])\n",
            "x @ v:  torch.Size([1, 12, 95, 64])\n",
            "Transpose x:  torch.Size([1, 95, 12, 64])\n",
            "x.view:  torch.Size([1, 95, 768])\n",
            "self.c_proj(x):  torch.Size([1, 95, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 768]) torch.Size([1, 97, 768]) torch.Size([1, 97, 768])\n",
            "torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64]) torch.Size([1, 97, 12, 64])\n",
            "torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64]) torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 12, 97, 97])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 97, 97])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 97, 97])\n",
            "softmax x:  torch.Size([1, 12, 97, 97])\n",
            "x @ v:  torch.Size([1, 12, 97, 64])\n",
            "Transpose x:  torch.Size([1, 97, 12, 64])\n",
            "x.view:  torch.Size([1, 97, 768])\n",
            "self.c_proj(x):  torch.Size([1, 97, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 768]) torch.Size([1, 109, 768]) torch.Size([1, 109, 768])\n",
            "torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64]) torch.Size([1, 109, 12, 64])\n",
            "torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64]) torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 12, 109, 109])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 109, 109])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 109, 109])\n",
            "softmax x:  torch.Size([1, 12, 109, 109])\n",
            "x @ v:  torch.Size([1, 12, 109, 64])\n",
            "Transpose x:  torch.Size([1, 109, 12, 64])\n",
            "x.view:  torch.Size([1, 109, 768])\n",
            "self.c_proj(x):  torch.Size([1, 109, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 768]) torch.Size([1, 102, 768]) torch.Size([1, 102, 768])\n",
            "torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64]) torch.Size([1, 102, 12, 64])\n",
            "torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64]) torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 12, 102, 102])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 102, 102])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 102, 102])\n",
            "softmax x:  torch.Size([1, 12, 102, 102])\n",
            "x @ v:  torch.Size([1, 12, 102, 64])\n",
            "Transpose x:  torch.Size([1, 102, 12, 64])\n",
            "x.view:  torch.Size([1, 102, 768])\n",
            "self.c_proj(x):  torch.Size([1, 102, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 768]) torch.Size([1, 92, 768]) torch.Size([1, 92, 768])\n",
            "torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64]) torch.Size([1, 92, 12, 64])\n",
            "torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64]) torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 12, 92, 92])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 92, 92])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 92, 92])\n",
            "softmax x:  torch.Size([1, 12, 92, 92])\n",
            "x @ v:  torch.Size([1, 12, 92, 64])\n",
            "Transpose x:  torch.Size([1, 92, 12, 64])\n",
            "x.view:  torch.Size([1, 92, 768])\n",
            "self.c_proj(x):  torch.Size([1, 92, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 768]) torch.Size([1, 122, 768]) torch.Size([1, 122, 768])\n",
            "torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64]) torch.Size([1, 122, 12, 64])\n",
            "torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64]) torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 12, 122, 122])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 122, 122])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 122, 122])\n",
            "softmax x:  torch.Size([1, 12, 122, 122])\n",
            "x @ v:  torch.Size([1, 12, 122, 64])\n",
            "Transpose x:  torch.Size([1, 122, 12, 64])\n",
            "x.view:  torch.Size([1, 122, 768])\n",
            "self.c_proj(x):  torch.Size([1, 122, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 768]) torch.Size([1, 118, 768]) torch.Size([1, 118, 768])\n",
            "torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64]) torch.Size([1, 118, 12, 64])\n",
            "torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64]) torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 12, 118, 118])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 118, 118])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 118, 118])\n",
            "softmax x:  torch.Size([1, 12, 118, 118])\n",
            "x @ v:  torch.Size([1, 12, 118, 64])\n",
            "Transpose x:  torch.Size([1, 118, 12, 64])\n",
            "x.view:  torch.Size([1, 118, 768])\n",
            "self.c_proj(x):  torch.Size([1, 118, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 768]) torch.Size([1, 124, 768]) torch.Size([1, 124, 768])\n",
            "torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64]) torch.Size([1, 124, 12, 64])\n",
            "torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64]) torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 12, 124, 124])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 124, 124])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 124, 124])\n",
            "softmax x:  torch.Size([1, 12, 124, 124])\n",
            "x @ v:  torch.Size([1, 12, 124, 64])\n",
            "Transpose x:  torch.Size([1, 124, 12, 64])\n",
            "x.view:  torch.Size([1, 124, 768])\n",
            "self.c_proj(x):  torch.Size([1, 124, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 768]) torch.Size([1, 101, 768]) torch.Size([1, 101, 768])\n",
            "torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64]) torch.Size([1, 101, 12, 64])\n",
            "torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64]) torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 12, 101, 101])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 101, 101])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 101, 101])\n",
            "softmax x:  torch.Size([1, 12, 101, 101])\n",
            "x @ v:  torch.Size([1, 12, 101, 64])\n",
            "Transpose x:  torch.Size([1, 101, 12, 64])\n",
            "x.view:  torch.Size([1, 101, 768])\n",
            "self.c_proj(x):  torch.Size([1, 101, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 768]) torch.Size([1, 78, 768]) torch.Size([1, 78, 768])\n",
            "torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64]) torch.Size([1, 78, 12, 64])\n",
            "torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64]) torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 12, 78, 78])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 78, 78])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 78, 78])\n",
            "softmax x:  torch.Size([1, 12, 78, 78])\n",
            "x @ v:  torch.Size([1, 12, 78, 64])\n",
            "Transpose x:  torch.Size([1, 78, 12, 64])\n",
            "x.view:  torch.Size([1, 78, 768])\n",
            "self.c_proj(x):  torch.Size([1, 78, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 768]) torch.Size([1, 96, 768]) torch.Size([1, 96, 768])\n",
            "torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64]) torch.Size([1, 96, 12, 64])\n",
            "torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64]) torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 12, 96, 96])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 96, 96])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 96, 96])\n",
            "softmax x:  torch.Size([1, 12, 96, 96])\n",
            "x @ v:  torch.Size([1, 12, 96, 64])\n",
            "Transpose x:  torch.Size([1, 96, 12, 64])\n",
            "x.view:  torch.Size([1, 96, 768])\n",
            "self.c_proj(x):  torch.Size([1, 96, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 768]) torch.Size([1, 90, 768]) torch.Size([1, 90, 768])\n",
            "torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64]) torch.Size([1, 90, 12, 64])\n",
            "torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64]) torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 12, 90, 90])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 90, 90])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 90, 90])\n",
            "softmax x:  torch.Size([1, 12, 90, 90])\n",
            "x @ v:  torch.Size([1, 12, 90, 64])\n",
            "Transpose x:  torch.Size([1, 90, 12, 64])\n",
            "x.view:  torch.Size([1, 90, 768])\n",
            "self.c_proj(x):  torch.Size([1, 90, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Input x: torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 768]) torch.Size([1, 91, 768]) torch.Size([1, 91, 768])\n",
            "torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64]) torch.Size([1, 91, 12, 64])\n",
            "torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64]) torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 12, 91, 91])\n",
            "x / head_embd**0.5:  torch.Size([1, 12, 91, 91])\n",
            "x + self.mask[:seq_len, :seq_len] x:  torch.Size([1, 12, 91, 91])\n",
            "softmax x:  torch.Size([1, 12, 91, 91])\n",
            "x @ v:  torch.Size([1, 12, 91, 64])\n",
            "Transpose x:  torch.Size([1, 91, 12, 64])\n",
            "x.view:  torch.Size([1, 91, 768])\n",
            "self.c_proj(x):  torch.Size([1, 91, 768])\n",
            "Accuracy: 30.47%\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"hellaswag-mini.jsonl\") as f:\n",
        "    n_correct = 0 # number of correctly predicted samples.\n",
        "    n_total = 0 # total number of samples processed.\n",
        "    for line in f:\n",
        "        sample = json.loads(line) # Parses the current JSON line into a Python dictionary 'sample'.\n",
        "        prefix = tokenizer.encode(sample[\"ctx\"]) # Tokenizes the context.\n",
        "        ending_scores = []\n",
        "        for i, ending in enumerate(sample[\"endings\"]): # Iterates through the list of endings for the context.\n",
        "            suffix = tokenizer.encode(\" \" + ending) # Tokenizes the current ending.\n",
        "            context = torch.tensor([prefix + suffix], dtype=torch.long) # Combines prefix and suffix tokens.\n",
        "            with torch.no_grad(): # disables gradient calculation (to save resources).\n",
        "                logits = model(context) # Generating logits.\n",
        "                ending_score = torch.nn.functional.cross_entropy( # Calculates the negative log likelihood as the score for this ending.\n",
        "                    logits[0, -len(suffix) - 1 : -1], context[0, -len(suffix) :] # Compares the logits against the actual suffix tokens.\n",
        "                )\n",
        "            ending_scores.append((ending_score, i)) # Stores the calculated score (loss) and the index 'i' of the current ending.\n",
        "        predicted = min(ending_scores)[1] # fetching the index of the ending with the minimum score.\n",
        "        n_correct += int(predicted == sample[\"label\"])\n",
        "        n_total += 1\n",
        "    print(f\"Accuracy: {n_correct / n_total:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2CxJjmvVGDK"
      },
      "source": [
        "**HellaSwag** is used to test the model's ability in understanding the context, this is done by using a methods called Adversial filtering that generate a correct ending and multiple of worng ends to trick the models, this technique showed that the models found hard time selecting the correct answer with accuracay dropped from 86.7% to 46% for state of the art model called BERT.\n",
        "\n",
        "**The expected predictions** is the follow up sentence that complete the context\n",
        "The models scores is based on their accuracy based on their selection of the 4 options that is been generated to trick the model. and then the result is compared with humans (they reached 95.6% accuracy) and random baseline (28% accuracy), the random baseline is a techniuqe that is similar to a technique I used to do whenever I have a multiple choice qustion and I have no clue about the answer, so in this case just pick one random option.\n",
        "\n",
        "The scoring for the ending is done through Cross-Entropy Loss, which measures how well the model predicted the sequence of tokens that built the ending.\n",
        "**Slicing Rationale** it aligns the logits with the true tokens by shifting the logits one position to the left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6OuzJ3zGbqN"
      },
      "source": [
        "**ðŸ¥³ Congratulations on finishing lab&nbsp;2!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
